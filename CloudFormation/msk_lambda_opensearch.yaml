Description: MSK OS Lambda resources

Resources:
  
  # -----------------
  # VPC
  # ----------------- 
  VPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: '10.0.0.0/16'
      Tags:
        - Key: Name
          Value: msk-vpc
      EnableDnsSupport: True
      EnableDnsHostnames: True

  # -----------------
  # Internet Gateway
  # -----------------
  VPCInternetGateway:
    Type: AWS::EC2::InternetGateway
    Properties:
      Tags:
        - Key: Name
          Value: msk-internet-gateway
  # Attach InternetGateway to VPC
  AttachInternetGatewayVPC:
    Type: 'AWS::EC2::VPCGatewayAttachment'
    Properties:
      InternetGatewayId: 
        Ref: VPCInternetGateway
      VpcId:
        Ref: VPC

  # -----------------
  # Subnets
  # ----------------- 

  #
  # Subnet 1
  #
  Subnet1:
    Type: AWS::EC2::Subnet
    Properties:
      CidrBlock: '10.0.0.0/28'
      AvailabilityZone: 'us-east-1a'
      VpcId: !Ref VPC
      Tags:
        - Key: Name
          Value: msk-subnet-1 | us-east-1a

  #
  # Subnet 2
  #
  Subnet2:
    Type: AWS::EC2::Subnet
    Properties:
      CidrBlock: '10.0.1.0/28'
      AvailabilityZone: 'us-east-1b'
      VpcId: !Ref VPC
      Tags:
        - Key: Name
          Value: msk-subnet-2 | us-east-1b

  # -----------------
  # Network Security Groups
  # -----------------
  
  #
  # MSK Security Group
  #   
  MSKSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupName: 'msk security group'
      GroupDescription: 'msk security group'
      VpcId: !Ref VPC
      # Egress rules
      SecurityGroupEgress:
        - IpProtocol: -1
          FromPort: -1 
          ToPort: -1
          CidrIp: '0.0.0.0/0'
      Tags:
        - Key: Name
          Value: 'msk security group'
  # add a self reference ingress rule 
  MSKSecurityGroupIngress1:
    Type: 'AWS::EC2::SecurityGroupIngress'
    Properties:
      # Ingress rules
      GroupId: !Ref MSKSecurityGroup
      IpProtocol: -1
      FromPort: -1
      ToPort: -1
      SourceSecurityGroupId: !GetAtt MSKSecurityGroup.GroupId

  # add inbound rule for Cloud9 SG
  # ?

  # -----------------
  # Route Table
  # -----------------
  VPCRouteTable:
    Type: AWS::EC2::RouteTable
    Properties: 
      Tags: 
        - Key: Name
          Value: msk-route-table
      VpcId: !Ref VPC
  # add a route to the internet gateway
  InternetGatewayRoute:
    Type: AWS::EC2::Route
    Properties: 
      RouteTableId: !Ref VPCRouteTable
      DestinationCidrBlock: '0.0.0.0/0'
      GatewayId: !Ref VPCInternetGateway

  # associate route table with subnets (Subnet1, Subnet2)
  Subnet1Association:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties: 
      RouteTableId: !Ref VPCRouteTable
      SubnetId: !Ref Subnet1

  Subnet2Association:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      RouteTableId: !Ref VPCRouteTable
      SubnetId: !Ref Subnet2

  # -----------------
  # MSK
  # -----------------
  MSKCluster:
    Type: AWS::MSK::Cluster
    Properties:
      ClusterName: 'msk-workshop-cluster'
      KafkaVersion: 2.6.2
      NumberOfBrokerNodes: 2
      BrokerNodeGroupInfo:
        InstanceType: kafka.m5.large
        ClientSubnets: 
          - !Ref Subnet1
          - !Ref Subnet2
        SecurityGroups:
          - !GetAtt MSKSecurityGroup.GroupId
        StorageInfo: 
          EBSStorageInfo: 
            VolumeSize: 100
      ClientAuthentication: 
        Unauthenticated: 
          Enabled: True
      EncryptionInfo:
        EncryptionInTransit: 
          ClientBroker: PLAINTEXT
          InCluster: False

  # -----------------
  # Cloud9
  # -----------------
  Cloud9:
    Type: AWS::Cloud9::EnvironmentEC2
    Properties:
      Name: 'msk-workshop-cloud9'
      Description: 'Cloud9 development enviorment'
      ImageId: 'amazonlinux-2-x86_64'
      InstanceType: 'm5.large'
      AutomaticStopTimeMinutes: '30'
      SubnetId: !Ref Subnet1
      Repositories: [
        {
          "PathComponent" : '/Kafka_OpenSearch_Anomaly_Detection',
          "RepositoryUrl" : 'https://github.com/ev2900/Kafka_OpenSearch_Anomaly_Detection.git'
        }
]

  # -----------------
  # VPC Endpoints
  # -----------------

  #
  # Lambda VPC Endpoint
  #
  LambdaVPCEndPoint:
    Type: AWS::EC2::VPCEndpoint
    Properties:
      VpcEndpointType: Interface
      PrivateDnsEnabled: True
      VpcId: !Ref VPC
      SubnetIds:
        - !Ref Subnet1
        - !Ref Subnet2 
      ServiceName: !Sub 'com.amazonaws.${AWS::Region}.lambda'
      SecurityGroupIds:
        - !GetAtt MSKSecurityGroup.GroupId

  #
  # STS VPC Endpoint
  #
  STSVPCEndPoint:
    Type: AWS::EC2::VPCEndpoint
    Properties:
      VpcEndpointType: Interface
      PrivateDnsEnabled: True
      VpcId: !Ref VPC
      SubnetIds:
        - !Ref Subnet1
        - !Ref Subnet2 
      ServiceName: !Sub 'com.amazonaws.${AWS::Region}.sts'
      SecurityGroupIds:
        - !GetAtt MSKSecurityGroup.GroupId

  # -----------------
  # OpenSearch
  # -----------------
  OpenSearchDomain:
    Type: AWS::OpenSearchService::Domain
    Properties:
      DomainName: workshop-domain
      EngineVersion: 'OpenSearch_1.2'
      # Development configuration
      ClusterConfig:
        DedicatedMasterEnabled: false
        InstanceCount: '1'
        ZoneAwarenessEnabled: false
        InstanceType: 'r6g.large.search'
      EBSOptions:
        EBSEnabled: true
        VolumeSize: '20'
      # Node to node encrpytion must be enabled to use the advanced security options
      NodeToNodeEncryptionOptions:
        Enabled: true
      # Encryption at rest must be ebabled to use the advanced security options
      EncryptionAtRestOptions:
        Enabled: true
      # HTTPS must be required to use the advanced security options
      DomainEndpointOptions:
        EnforceHTTPS: true
      # Create a master user with a pre-defined username and password
      AdvancedSecurityOptions:
        Enabled: true
        InternalUserDatabaseEnabled: true
        MasterUserOptions:
          MasterUserName: 'OSMasterUser'
          MasterUserPassword: 'AwS#OpenSearch1'
      # Set an access policy open to any AWS resource
      AccessPolicies:
        Version: 2012-10-17
        Statement:
          Effect: 'Allow'
          Principal:
            AWS: '*'
          Action: 'es:*'
          Resource: '*'

  # -----------------
  # IAM Role
  # -----------------
  LambdaIAMRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: 'Lambda-MSK-OpenSearch-Role'
      Description: 'IAM role for Lambda Function to use'
      # Trust relationships
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      # Premissions
      Policies:
        # Firehose premissions
        - PolicyName: vpc_access
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action: 'ec2:*'
                Resource: '*'
        # OpenSearch premissions
        - PolicyName: lambda_logs
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action: 'logs:*'
                Resource: '*'
        # S3
        - PolicyName: msk
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action: 'kafka:*'
                Resource: '*'

  # -----------------
  # Lambda
  # ----------------- 
  VPCInternetGateway:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: 'msk-os-lambda'
      Runtime: 'python3.7'
      Architectures:
        - 'x86_64'
      Role: !GetAtt LambdaIAMRole.Arn
      Handler: 'index.lambda_handler'
      Code: 
        ZipFile: |
          import json
          import base64
          import re
          import urllib3
          import time
          import re

          def lambda_handler(event, context):

            # Decode Kafka message(s)
            partition0 = event['records']
            messages_raw = partition0['ApplicationMetricTopic-0']

            print('Batch size = ' + str(len(messages_raw)) + ' messages')

            for message_raw in messages_raw:
                
                topic = message_raw['topic']
                partition = message_raw['partition']
                offset = message_raw['offset']
                timestamp = message_raw['timestamp']
                timestampType = message_raw['timestampType']
                value = message_raw['value']
                                
                decoded_b64_message_value = base64.b64decode(value)
                decoded_utf8_message_value = decoded_b64_message_value.decode("utf-8")
                                
                decoded_utf8_message_value_dict = json.loads(decoded_utf8_message_value.replace("'", "\""))
                
                print('Raw message from Kafak = ' + str(decoded_utf8_message_value_dict))
                
                # Send message(s) to OpenSearch
                            
                http = urllib3.PoolManager()
                            
                os_url = '<os_domain_endpoint_url>'
                                    
                insert_document_r_body = {
                  "eventtime": decoded_utf8_message_value_dict['eventtime'],
                  "application_id": decoded_utf8_message_value_dict['application_id'],
                  "cpu_util": int(decoded_utf8_message_value_dict['cpu_util']),
                  "memory_util": int(decoded_utf8_message_value_dict['memory_util']),
                  "disk_util": int(decoded_utf8_message_value_dict['disk_util'])
                }
                
                print('Processing message # ' + str(decoded_utf8_message_value_dict['message_id']))
                
                full_url = os_url + '/infa-logs-1/_doc/' + str(decoded_utf8_message_value_dict['message_id'])

                print('Request URL = ' + full_url)
                print('Request body = ' + str(insert_document_r_body))
                    
                auth_header = urllib3.make_headers(basic_auth='OSMasterUser:AwS#OpenSearch1')
                
                resp = http.request(
                    'PUT',
                    full_url,
                    body=json.dumps(insert_document_r_body),
                    headers={'Content-Type': 'application/json', 'authorization': auth_header['authorization']}
                )
                
                print('Request sent!')
                print('Response status = ' + str(resp.status))
                print(resp.headers)
                print('Response body = ' + str(resp.data.decode('utf-8')))
                
            return {
                'statusCode': 200,
                'body': json.dumps('Success')
            }
           
Outputs:
  UserName:
    Description: 'OpenSearch Dashboard Login UserName'
    Value: 'OSMasterUser'
  Password:
    Description: 'OpenSearch Dashboard Login Password'
    Value: 'AwS#OpenSearch1'
  OSDomainURL:
    Description: 'OpenSearch domain endpoint URL'
    Value: !Join [ "", [ "https://", !GetAtt OpenSearchDomain.DomainEndpoint] ]
  IAMUserARN:
    Description: 'ARN of the IAM role LambdaIAMRole'
    Value: !GetAtt LambdaIAMRole.Arn